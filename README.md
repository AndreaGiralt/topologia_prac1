# PrÃ¡ctica 1: TopologÃ­a y ciclo de vida de los datos
Webscraper a la web de pisos.com

## DescripciÃ³n
Esta prÃ¡ctica se ha realizado bajo el contexto de la asignatura TipologÃ­a y ciclo de vida de los datos, perteneciente al MÃ¡ster en Ciencia de Datos de la Universitat Oberta de Catalunya. En ella, se aplican tÃ©cnicas de web scraping mediante el lenguaje de programaciÃ³n Python para extraer asÃ­ datos de las webs Pisos.com y datos.gob.es y generar un dataset.

## Miembros del equipo
La actividad ha sido realizada por Andrea Giralt y Manuel Fernandez. 

## Documento con las respuestas
* [Documento con la memoria de la prÃ¡ctica en pdf](docs/memoria.pdf)

## Video explicativo
* [Enlace al video explicativo](https://drive.google.com/file/d/1hQHQwDLWJeYcxgqUthmUtMuxVzqhWgd8/view?usp=sharing)

## Ejecutar el spider
Desde una terminal, lanzar el comando.
En una terminal compatible con linux (WSL2 o macOS) Para ver los comandos disponibles ejecutamos:

```bash
make help 
```

El sistema nos mostrarÃ¡ por pantalla las siguientes opciones:
```
ğŸš€ local : build and launch local environment
ğŸ–¥ï¸ console : open a python console
ğŸ•·ï¸ spider: runs the complete spider
ğŸ•·ï¸ zones: runs zones spider
ğŸ•·ï¸ previews: runs previews spider
ğŸ•·ï¸ details: runs details spider
ğŸ’¾ csv: dump into csv
ğŸ—‚ï¸ dump : dump database
ğŸ start : starts environment
ğŸ›‘ stop : stops environment
ğŸ—‘ï¸ remove : remove all containers
```

* ```local```:Arranca los contenedores docker necesarios para ejecutar el spider.
* ```console```: Inicia una consola dentro del contenedor de python (Es Ãºtil si se quiere ejecutar una parte del *spider*)
* ```spider```: Lanza todas las tares del spider al completo.
* ```zones```: Importa las zonas del mapa de Mallorca.
* ```previews```: Extrae la informaciÃ³n que aparece en los listados de bÃºsquedas.
* ```details```: Extrae informaciÃ³n complementaria como coordenadas en el mapa, propietario del anuncio...
* ```csv```: Genera el csv ```data/real_states.csv``` con la informaciÃ³n extraida de las web de pisos.com
* ```dump```: Realiza un dump de la base de datos.
* ```start```: Arranca el entorno
* ```stop```: Para el entorno.
* ```remove```: Borra todos los contenedores.


## Script ```parser```
Para acceder al contenedor de python, ejecutamos la instrucciÃ³n:
```
make console
```
Una vez dentro, ejecutamos la siguiente instrucciÃ³n para ver quÃ© opciones nos da el comando ```parser```:
```
./parser -h
```
Nos aparecerÃ¡n las siguientes opciones:
```
usage: parser [-h] [-a] [-z] [-p] [-d] [-u] [-c]

Scraper de la web pisos.com (Mallorca)

options:
  -h, --help          show this help message and exit
  -a, --all           Importa todo
  -z, --zones         Importa las zonas de Mallorca.
  -p, --previews      Importa datos bÃ¡sicos de los anuncios
  -d, --details       Importa los detalles de los anuncios.
  -u, --unemployment  Importa el paro registrado por municipios.
  -c, --csv           Crea un csv con los resultados.
```

